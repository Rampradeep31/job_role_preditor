{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c6d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Data from: D:\\infosys\\job_role_preditor\\dataset\\education_career_success_UPDATED.csv\n",
      "üß† Extracting Skill Features...\n",
      "\n",
      "üìä Calculating Accuracy...\n",
      "========================================\n",
      "üéØ NEW ACCURACY SCORE: 87.10%\n",
      "========================================\n",
      "\n",
      "üíæ Saving updated models...\n",
      "‚úÖ All models saved to ../backend/database/ml/models/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA\n",
    "# ==========================================\n",
    "csv_path = r\"D:\\infosys\\job_role_preditor\\dataset\\education_career_success_UPDATED.csv\"\n",
    "print(f\"üìÇ Loading Data from: {csv_path}\")\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    print(\"‚ùå Error: File not found! Check the path.\")\n",
    "    exit()\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ==========================================\n",
    "# 1.1 AUTO-FIX COLUMN NAMES\n",
    "# ==========================================\n",
    "df.columns = df.columns.str.strip()\n",
    "rename_map = {\n",
    "    'Internship': 'Internships_Completed',\n",
    "    'Internships': 'Internships_Completed',\n",
    "    'GPA': 'University_GPA',\n",
    "    'CGPA': 'University_GPA',\n",
    "    'Specialization': 'Field_of_Study',\n",
    "    'Certification': 'Certifications',\n",
    "    'Certifications': 'Certifications',\n",
    "    'Job_Roles': 'Job_Role',\n",
    "    'Role': 'Job_Role'\n",
    "}\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Basic Cleanup\n",
    "df['Job_Role'] = df['Job_Role'].replace({'Software Engineer': 'Software Developer'})\n",
    "df['Internships_Completed'] = df['Internships_Completed'].fillna(0)\n",
    "df['University_GPA'] = df['University_GPA'].fillna(0.0)\n",
    "df['Certifications'] = df['Certifications'].fillna(\"None\").astype(str).str.lower()\n",
    "df['Field_of_Study'] = df['Field_of_Study'].fillna('Other').astype(str).str.strip()\n",
    "df['Degree'] = df['Degree'].fillna('Other').astype(str).str.strip() # Ensure Degree is clean\n",
    "\n",
    "# ==========================================\n",
    "# 2. FEATURE ENGINEERING (The Upgrade)\n",
    "# ==========================================\n",
    "\n",
    "# A. KEY SKILLS (This boosts accuracy significantly)\n",
    "KEY_SKILLS = ['python', 'java', 'aws', 'react', 'cpa', 'autocad', 'scrum', 'six sigma']\n",
    "print(\"üß† Extracting Skill Features...\")\n",
    "\n",
    "skill_flags = []\n",
    "for skill in KEY_SKILLS:\n",
    "    col_name = f'Has_{skill}'\n",
    "    # Create the column\n",
    "    df[col_name] = df['Certifications'].apply(lambda x: 1 if skill in x else 0)\n",
    "    skill_flags.append(col_name)\n",
    "\n",
    "# B. Cert Count\n",
    "def count_certs(val):\n",
    "    if val == \"none\" or not val.strip(): return 0\n",
    "    return len(val.split(','))\n",
    "df['Certifications_Count'] = df['Certifications'].apply(count_certs)\n",
    "\n",
    "# ==========================================\n",
    "# 3. ENCODING & SCALING\n",
    "# ==========================================\n",
    "\n",
    "# A. Degree (CRITICAL MISSING PIECE)\n",
    "le_degree = LabelEncoder()\n",
    "df['Degree_Encoded'] = le_degree.fit_transform(df['Degree'])\n",
    "\n",
    "# B. Field\n",
    "le_field = LabelEncoder()\n",
    "df['Field_Encoded'] = le_field.fit_transform(df['Field_of_Study'])\n",
    "\n",
    "# C. GPA\n",
    "scaler = MinMaxScaler()\n",
    "df['GPA_Scaled'] = scaler.fit_transform(df[['University_GPA']])\n",
    "\n",
    "# D. Target\n",
    "le_target = LabelEncoder()\n",
    "df['Role_Encoded'] = le_target.fit_transform(df['Job_Role'])\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREPARE X AND Y\n",
    "# ==========================================\n",
    "# We combine: Degree + Field + GPA + Cert Count + Internships + Specific Skills\n",
    "feature_cols = ['Degree_Encoded', 'Field_Encoded', 'GPA_Scaled', 'Certifications_Count', 'Internships_Completed'] + skill_flags\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['Role_Encoded'].values\n",
    "\n",
    "# ==========================================\n",
    "# 5. TRAIN & EVALUATE\n",
    "# ==========================================\n",
    "print(\"\\nüìä Calculating Accuracy...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(f\"üéØ NEW ACCURACY SCORE: {acc * 100:.2f}%\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# ==========================================\n",
    "# 6. SAVE MODELS\n",
    "# ==========================================\n",
    "print(\"\\nüíæ Saving updated models...\")\n",
    "save_path = '../backend/database/ml/models/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "with open(save_path + 'model.pkl', 'wb') as f: pickle.dump(model, f)\n",
    "with open(save_path + 'degree_encoder.pkl', 'wb') as f: pickle.dump(le_degree, f) # Save Degree Encoder\n",
    "with open(save_path + 'field_encoder.pkl', 'wb') as f: pickle.dump(le_field, f)\n",
    "with open(save_path + 'scaler.pkl', 'wb') as f: pickle.dump(scaler, f)\n",
    "with open(save_path + 'target_encoder.pkl', 'wb') as f: pickle.dump(le_target, f)\n",
    "\n",
    "print(f\"‚úÖ All models saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
